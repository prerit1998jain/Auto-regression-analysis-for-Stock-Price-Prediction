{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('STOCK.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data[10000:].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(data[9500:10000].Open.rolling(1).sum())\n",
    "plt.title('Data')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#ye_2017_normal = year_2017[:-35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(data[10000:].Open)\n",
    "plt.title('Data')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#ye_2017_normal = year_2017[:-35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(num=None, figsize=(30, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(data.index[10000:],data[10000:].High.rolling(10).sum(),data.index[10000:],data[10000:].Low.rolling(10).sum())\n",
    "\n",
    "plt.title('Data')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#ye_2017_normal = year_2017[:-35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['range'] = data.High - data.Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(data[11650:].range.rolling(15).sum())\n",
    "plt.title('Data')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "#ye_2017_normal = year_2017[:-35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = list(data[:12073].High.values)\n",
    "difference = list(data.High[1:] - copy)\n",
    "difference.append(0)\n",
    "data['difference'] = difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(data[10000:].difference.rolling(15).sum())\n",
    "plt.title('Data')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "X = data.High.values\n",
    "result = adfuller(X[:])\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "\tprint('\\t%s: %.3f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats.stats import pearsonr \n",
    "import datetime\n",
    "import multiprocessing\n",
    "import math\n",
    "\n",
    "#input file, formatted as having 2 columns: position, and value\n",
    "txn = pd.read_csv('STOCK.txt')\n",
    "#txn = txn.drop_duplicates()\n",
    "#txn_original = txn.copy()\n",
    "txn.drop(['High','Low','Close','Volume','OpenInt'],axis = 1, inplace = True)\n",
    "txn.columns = ['coord', 'value']\n",
    "#txn = txn.set_index('coord')\n",
    "\n",
    "MAX_LAG = 10\n",
    "\n",
    "LENGTH_GENOME = max(txn.index)\n",
    "\n",
    "# For each lag, this for loop identifies pairs of loci in the genome with that lag, and saves their \n",
    "# expression values in a list. Then it computes the correlations between the 2 lists.\n",
    "\n",
    "def pearson_correlation(numbers_x, numbers_y):\n",
    "    x = numbers_x - np.mean(numbers_x)\n",
    "    y = numbers_y - np.mean(numbers_y)\n",
    "    return (x * y).sum() / np.sqrt((x**2).sum() * (y**2).sum())\n",
    "\n",
    "def get_corr(lag):\n",
    "    exp1 = []\n",
    "    exp2 = []\n",
    "    for i in txn.index:\n",
    "        e1 = txn.value[i]\n",
    "        if (i + lag) > LENGTH_GENOME:\n",
    "            break\n",
    "        if (i + lag) in txn.index:\n",
    "            e2 = txn.value[i+lag]\n",
    "            print(e2)\n",
    "            if  hasattr(e1,\"__len__\"):\n",
    "                e1 = e1.iloc[0]\n",
    "            if  hasattr(e2,\"__len__\"):\n",
    "                e2 = e2.iloc[0]\n",
    "            exp1.append(e1)\n",
    "            exp2.append(e2)\n",
    "    return[lag, pearson_correlation(exp1,exp2)]\n",
    "\n",
    "RES = []\n",
    "for i in range(MAX_LAG):\n",
    "    p = get_corr(i)\n",
    "    RES.append(p)\n",
    "\n",
    "lags = []\n",
    "cors = []\n",
    "for i in range(0, len(RES)):\n",
    "    lags.append(RES[i][0])\n",
    "    cors.append(RES[i][1])\n",
    "\n",
    "# Forming the correlation matrix\n",
    "def ACF_mat(cors):\n",
    "    corr_mat = []\n",
    "    for i in range(len(cors)):\n",
    "        lag_x = []\n",
    "        for j in range(MAX_LAG):\n",
    "            lag_x.append(cors[abs(j-i)])\n",
    "        corr_mat.append(lag_x)\n",
    "    return(corr_mat)\n",
    "\n",
    "cor_mat = ACF_mat(cors)\n",
    "def AR_Params(ACF_mat):\n",
    "    beta = np.random.rand(len(ACF_mat))\n",
    "    beta = np.dot(np.linalg.inv(ACF_mat),ACF_mat[0])\n",
    "    return(beta)    \n",
    "\n",
    "beta = AR_Params(cor_mat)\n",
    "print(\"This is BETA\")\n",
    "print(beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in corr_mat.index:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(numbers_x, numbers_y):\n",
    "    x = numbers_x - np.mean(numbers_x)\n",
    "    y = numbers_y - np.mean(numbers_y)\n",
    "    return (x * y).sum() / np.sqrt((x**2).sum() * (y**2).sum())\n",
    "\n",
    "def get_cors(lag):\n",
    "    exp1 = []\n",
    "    exp2 = []\n",
    "    LENGTH_GENOME = len(data)\n",
    "    data_index = [i for i in range(LENGTH_GENOME)]\n",
    "    for i in range(len(data)):\n",
    "        e1 = data[i]\n",
    "        if (i + lag) > LENGTH_GENOME:\n",
    "            break\n",
    "        if (i + lag) in data_index:\n",
    "            e2 = data[i+lag]\n",
    "            print(e2)\n",
    "            exp1.append(e1)\n",
    "            exp2.append(e2)                \n",
    "        return(pearson_correlation(exp1,exp2))\n",
    "\n",
    "class AR_MODEL:\n",
    "    def __init__(self, lag, data):\n",
    "        self.lag = lag\n",
    "        self.data = data \n",
    "        \n",
    "    def ACF_mat(self, max_lag):\n",
    "        cors = []\n",
    "        for i in range(max_lag):\n",
    "            cors.append(get_cors(i))\n",
    "        corr_mat = []\n",
    "        for i in range(len(cors)):\n",
    "            lag_x = []\n",
    "            for j in range(max_lag):\n",
    "                lag_x.append(cors[abs(j-i)])\n",
    "            corr_mat.append(lag_x)\n",
    "        return(corr_mat)\n",
    "        \n",
    "    def model_params(self, max_lag, data):\n",
    "        beta = np.random.rand(max_lag)\n",
    "        mat = self.ACF_mat(max_lag, data)\n",
    "        beta = np.dot(np.linalg.inv(mat),mat[0])\n",
    "        return(beta)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AR_MODEL(10, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ACF_mat(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "x = np.array([[1,2],[3,4]]) \n",
    "y = np.linalg.inv(x) \n",
    "print(x) \n",
    "print(y) \n",
    "print(np.dot(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is correlation matrix \n",
      "\n",
      "[[1.0, 0.9994612499306779, 0.9989083421536935, 0.9983723118285689, 0.9978288491985361, 0.9972949462557793, 0.9967568455377309, 0.9962000482616908, 0.9956476385987072, 0.9950757022954487], [0.9994612499306779, 1.0, 0.9994612499306779, 0.9989083421536935, 0.9983723118285689, 0.9978288491985361, 0.9972949462557793, 0.9967568455377309, 0.9962000482616908, 0.9956476385987072], [0.9989083421536935, 0.9994612499306779, 1.0, 0.9994612499306779, 0.9989083421536935, 0.9983723118285689, 0.9978288491985361, 0.9972949462557793, 0.9967568455377309, 0.9962000482616908], [0.9983723118285689, 0.9989083421536935, 0.9994612499306779, 1.0, 0.9994612499306779, 0.9989083421536935, 0.9983723118285689, 0.9978288491985361, 0.9972949462557793, 0.9967568455377309], [0.9978288491985361, 0.9983723118285689, 0.9989083421536935, 0.9994612499306779, 1.0, 0.9994612499306779, 0.9989083421536935, 0.9983723118285689, 0.9978288491985361, 0.9972949462557793], [0.9972949462557793, 0.9978288491985361, 0.9983723118285689, 0.9989083421536935, 0.9994612499306779, 1.0, 0.9994612499306779, 0.9989083421536935, 0.9983723118285689, 0.9978288491985361], [0.9967568455377309, 0.9972949462557793, 0.9978288491985361, 0.9983723118285689, 0.9989083421536935, 0.9994612499306779, 1.0, 0.9994612499306779, 0.9989083421536935, 0.9983723118285689], [0.9962000482616908, 0.9967568455377309, 0.9972949462557793, 0.9978288491985361, 0.9983723118285689, 0.9989083421536935, 0.9994612499306779, 1.0, 0.9994612499306779, 0.9989083421536935], [0.9956476385987072, 0.9962000482616908, 0.9967568455377309, 0.9972949462557793, 0.9978288491985361, 0.9983723118285689, 0.9989083421536935, 0.9994612499306779, 1.0, 0.9994612499306779], [0.9950757022954487, 0.9956476385987072, 0.9962000482616908, 0.9967568455377309, 0.9972949462557793, 0.9978288491985361, 0.9983723118285689, 0.9989083421536935, 0.9994612499306779, 1.0]]\n",
      "This is BETA\n",
      "[ 1.00000000e+00 -9.94759830e-13  1.25055521e-12 -1.31450406e-12\n",
      "  2.70183875e-12 -1.58451030e-12 -2.30926389e-13  3.41060513e-13\n",
      " -1.13686838e-13  4.26325641e-14]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats.stats import pearsonr \n",
    "import datetime\n",
    "import multiprocessing\n",
    "import math\n",
    "\n",
    "#input file, formatted as having 2 columns: position, and value\n",
    "txn = pd.read_csv('STOCK.txt')\n",
    "#txn = txn.drop_duplicates()\n",
    "#txn_original = txn.copy()\n",
    "txn.drop(['High','Low','Close','Volume','OpenInt'],axis = 1, inplace = True)\n",
    "txn.columns = ['coord', 'value']\n",
    "#txn = txn.set_index('coord')\n",
    "\n",
    "MAX_LAG = 10\n",
    "\n",
    "LENGTH_GENOME = max(txn.index)\n",
    "\n",
    "# For each lag, this for loop identifies pairs of loci in the genome with that lag, and saves their \n",
    "# expression values in a list. Then it computes the correlations between the 2 lists.\n",
    "\n",
    "def pearson_correlation(numbers_x, numbers_y):\n",
    "    x = numbers_x - np.mean(numbers_x)\n",
    "    y = numbers_y - np.mean(numbers_y)\n",
    "    return (x * y).sum() / np.sqrt((x**2).sum() * (y**2).sum())\n",
    "\n",
    "def get_corr(lag):\n",
    "    exp1 = []\n",
    "    exp2 = []\n",
    "    for i in txn.index:\n",
    "        e1 = txn.value[i]\n",
    "        if (i + lag) > LENGTH_GENOME:\n",
    "            break\n",
    "        if (i + lag) in txn.index:\n",
    "            e2 = txn.value[i+lag]\n",
    "            #print(e2)\n",
    "            if  hasattr(e1,\"__len__\"):\n",
    "                e1 = e1.iloc[0]\n",
    "            if  hasattr(e2,\"__len__\"):\n",
    "                e2 = e2.iloc[0]\n",
    "            exp1.append(e1)\n",
    "            exp2.append(e2)\n",
    "    return([lag, pearson_correlation(exp1,exp2)])\n",
    "\n",
    "RES = []\n",
    "for i in range(MAX_LAG):\n",
    "    p = get_corr(i)\n",
    "    RES.append(p)\n",
    "\n",
    "lags = []\n",
    "cors = []\n",
    "for i in range(0, len(RES)):\n",
    "    lags.append(RES[i][0])\n",
    "    cors.append(RES[i][1])\n",
    "\n",
    "# Forming the correlation matrix\n",
    "def ACF_mat(cors):\n",
    "    corr_mat = []\n",
    "    for i in range(len(cors)):\n",
    "        lag_x = []\n",
    "        for j in range(MAX_LAG):\n",
    "            lag_x.append(cors[abs(j-i)])\n",
    "        corr_mat.append(lag_x)\n",
    "    return(corr_mat)\n",
    "\n",
    "cor_mat = ACF_mat(cors)\n",
    "print(\"This is correlation matrix \\n\")\n",
    "print(cor_mat)\n",
    "def AR_Params(ACF_mat):\n",
    "    beta = np.random.rand(len(ACF_mat))\n",
    "    beta = np.dot(np.linalg.inv(ACF_mat),ACF_mat[0])\n",
    "    return(beta)    \n",
    "\n",
    "beta = AR_Params(cor_mat)\n",
    "print(\"This is BETA\")\n",
    "print(beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
